{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6795ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5fa77584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ encoding-decoding section ------#\n",
    "'''\n",
    "Assuming data is an np.ndarray with shape (num_sample, 1), or at least an np.ndarray\n",
    "Assuming num_possible_value is an integer representing how many different possible values (by default it's 256)\n",
    "The return value should be an np.ndarray with shape (num_sample,num_possible_value)\n",
    "'''\n",
    "def one_hot_encode(data:np.ndarray, num_possible_value:int = 256) -> np.ndarray:\n",
    "\n",
    "    possible_values = np.arange(num_possible_value)\n",
    "    data = data.reshape((-1,1)) #just in case I miss something\n",
    "\n",
    "    re = np.cast['float32'](data==possible_values)\n",
    "    \n",
    "    return re\n",
    "\n",
    "'''\n",
    "Assuming data is an np.ndarray with shape (num_sample, num_possible_value)\n",
    "Shape won't be checked since most likely we don't need that\n",
    "The return value should be an np.ndarray with shape (num_sample,)\n",
    "'''\n",
    "def one_hot_decode(data:np.ndarray, axis=1) -> np.ndarray:\n",
    "    return data.argmax(axis)\n",
    "\n",
    "'''\n",
    "Assuming data is an np.ndarray with shape (num_sample,), it should be normalized to -1~1\n",
    "Assuming num_possible_value is an integer representing how many different possible values (by default it's 256)\n",
    "The return value should be an np.ndarray with shape (num_sample,)\n",
    "Based on a tensorflow implementation: \n",
    "    https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/ops.py\n",
    "tf.minimum will be ignored (since np.min doesn't support broadcasting)\n",
    "'''\n",
    "def mu_law_encode(data:np.ndarray, num_possible_value:int=256) -> np.ndarray:\n",
    "\n",
    "    #check if data is normalized\n",
    "    if (data>1.0).any() or (data<-1.0).any():\n",
    "        raise ValueError('Normalize Data First')\n",
    "\n",
    "    mu = float(num_possible_value-1)\n",
    "    data_abs = np.abs(data)\n",
    "    magnitude = np.log1p(mu*data_abs) / np.log1p(mu+1)\n",
    "    signal = np.sign(data) * magnitude\n",
    "\n",
    "    re = ((signal+1)/2 * mu +0.5)\n",
    "\n",
    "    return np.cast['int32'](re)\n",
    "\n",
    "'''\n",
    "Assuming data is an np.ndarray with shape (num_sample,)\n",
    "Assuming num_possible_value is an integer representing how many different possible values (by default it's 256)\n",
    "The return value should be an np.ndarray with shape (num_sample,)\n",
    "Based on a tensorflow implementation: \n",
    "    https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/ops.py\n",
    "'''\n",
    "def mu_law_decode(data:np.ndarray, num_possible_value:int=256) -> np.ndarray:\n",
    "\n",
    "    mu = num_possible_value - 1\n",
    "    signal = 2*(np.cast['float32'](data)/mu) - 1\n",
    "    magnitude = (1 / mu) * ((1 + mu)**np.abs(signal) - 1)\n",
    "\n",
    "    re = np.sign(signal) * magnitude\n",
    "\n",
    "    return re\n",
    "#------ encoding-decoding section finished ------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "109ccd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ data-loading section ------#\n",
    "'''\n",
    "Assuming file is an string representing the path of one audio file\n",
    "Assuming sr is the sample rate of the audio file (by default it's 16000) (why 16000? cuz 16kHz is pretty common for mp3)\n",
    "Since librosa supprots resampling, we don't really need to care about sampling that much\n",
    "However, according to https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/ops.py,\n",
    "resampling might cause error\n",
    "In that case, the best practice might be using the sample rate of the audio file (which can be modified in other methods)\n",
    "The return value should be an np.ndarray with shape (num_sample,)\n",
    "The return value should be normalized to -1~1 (done by librosa)\n",
    "'''\n",
    "def load_audio_file(file:str, sr:int=16000, trim:bool=True) -> np.ndarray:\n",
    "    \n",
    "    data, _ = librosa.load(file, sr=sr, mono=True)\n",
    "    if trim:\n",
    "        data, _ = librosa.effects.trim(data)\n",
    "\n",
    "    print(file)\n",
    "    print(data.shape)\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e5397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sub-class of data.Dataset\n",
    "It will iterate the folder containing sound files\n",
    "However, program WILL NOT check if it is a sound file,\n",
    "plz make sure all files under source folder are sound files\n",
    "'''\n",
    "class AudioDataset(data.Dataset):\n",
    "    '''\n",
    "    Assuming source_folder is a string representing the path to the folder with sound files\n",
    "    Assuming sr is an integer representing the sample rate (by default it's 16000)\n",
    "    Assuming num_possible_value is an integer representing how many different possible values (by default it's 256)\n",
    "    Assuming trim is a boolean representing whether removing blank at the beginning and the end or not\n",
    "    '''\n",
    "    def __init__(self, source_folder:str='AudioData', sr:int=16000, num_possible_value:int=256, trim=True):\n",
    "        super(AudioDataset, self).__init__()\n",
    "\n",
    "        self.num_possible_value = num_possible_value\n",
    "        self.sr = sr\n",
    "        self.trim = trim\n",
    "        self.source_folder = source_folder\n",
    "        self.file_list = [x for x in os.listdir(source_folder)]\n",
    "\n",
    "    '''\n",
    "    Override\n",
    "    Returning an np.ndarray representing an audio file at a time\n",
    "    Data will be one-hot encoded (in other words, each input sample will have 256 features instead of one)\n",
    "    '''\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        file_path = os.path.join(self.source_folder,\\\n",
    "                                 self.file_list[index])\n",
    "        \n",
    "        data = load_audio_file(file_path, self.sr, self.trim)\n",
    "        mu_encoded_data = mu_law_encode(data, self.num_possible_value) #training data\n",
    "        one_hot_encoded_data = one_hot_encode(mu_encoded_data, self.num_possible_value) #labels\n",
    "\n",
    "        return one_hot_encoded_data\n",
    "\n",
    "    '''\n",
    "    Override\n",
    "    Returnning the size of dataset\n",
    "    '''\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31c33dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sub-class of data.DataLoader\n",
    "It will generate training data and label pairs according to given params\n",
    "'''\n",
    "class AudioDataLoader(data.DataLoader):\n",
    "    def __init__(self, receptive_field:int,\\\n",
    "                        source_folder:str='AudioData',\\\n",
    "                        batch_size:int=1,\\\n",
    "                        sr:int=16000,\\\n",
    "                        num_possible_value:int=256,\\\n",
    "                        trim=True):\n",
    "\n",
    "        dataset = AudioDataset(source_folder, sr,num_possible_value, trim)\n",
    "        super(AudioDataLoader, self).__init__(dataset, batch_size, True) #True for shuffling\n",
    "\n",
    "        self.receptive_field = receptive_field\n",
    "        self.collate_fn = self.generate_training_pairs\n",
    "        self.has_gpu = torch.cuda.is_available()\n",
    "        self.sample_size = 10\n",
    "    \n",
    "    '''\n",
    "    Equivalent to torch.from_numpy\n",
    "    Autograd is guaranteed, use of gpu is guaranteed\n",
    "    '''\n",
    "    def numpy_to_variable(self, data: np.ndarray) -> torch.Tensor:\n",
    "\n",
    "        tensor = torch.from_numpy(data).float()\n",
    "        re = torch.autograd.Variable(tensor.cuda()) if self.has_gpu\\\n",
    "            else torch.autograd.Variable(tensor)\n",
    "\n",
    "        return re\n",
    "    @staticmethod\n",
    "    def _variable(data):\n",
    "        tensor = torch.from_numpy(data).float()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.autograd.Variable(tensor.cuda())\n",
    "        else:\n",
    "            return torch.autograd.Variable(tensor)\n",
    "        \n",
    "    def calc_sample_size(self, audio):\n",
    "        return self.sample_size if len(audio[0]) >= self.sample_size\\\n",
    "                                else len(audio[0])\n",
    "    '''\n",
    "    Customized collate_fn\n",
    "    '''\n",
    "    def generate_training_pairs(self, stacked_input):\n",
    "        audio = np.pad(stacked_input, [[0, 0], [self.receptive_field, 0], [0, 0]], 'constant')\n",
    "        \n",
    "        if self.sample_size:\n",
    "            sample_size = self.calc_sample_size(audio)\n",
    "\n",
    "            while sample_size > self.receptive_field:\n",
    "                inputs = audio[:, :sample_size, :]\n",
    "                targets = audio[:, self.receptive_field:sample_size, :]\n",
    "\n",
    "                yield self._variable(inputs),\\\n",
    "                      self._variable(one_hot_decode(targets, 2))\n",
    "\n",
    "                audio = audio[:, sample_size-self.receptive_field:, :]\n",
    "                sample_size = self.calc_sample_size(audio)\n",
    "        else:\n",
    "            targets = audio[:, self.receptive_field:, :]\n",
    "            return self._variable(audio),\\\n",
    "                   self._variable(one_hot_decode(targets, 2))\n",
    "        \n",
    "        #return mu_encoded_data, one_hot_encoded_data\n",
    "#------ data-loading section finished ------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "087fe20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataLoader(data.DataLoader):\n",
    "    def __init__(self, receptive_field:int,\\\n",
    "                        source_folder:str='AudioData',\\\n",
    "                        batch_size:int=1,\\\n",
    "                        sr:int=16000,\\\n",
    "                        num_possible_value:int=256,\\\n",
    "                        trim=True):\n",
    "\n",
    "        dataset = AudioDataset(source_folder, sr,num_possible_value, trim)\n",
    "        super(AudioDataLoader, self).__init__(dataset, 1, True) #True for shuffling\n",
    "\n",
    "        self.receptive_field = receptive_field\n",
    "        self.pseudo_batch = batch_size #batch NOT created by reading several sound file at a time\n",
    "                                        #instead, it should be created from a single file\n",
    "        self.collate_fn = self.generate_training_pairs\n",
    "        self.has_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    '''\n",
    "    Equivalent to torch.from_numpy\n",
    "    Autograd is guaranteed, use of gpu is guaranteed\n",
    "    '''\n",
    "    def numpy_to_variable(self, data: np.ndarray) -> torch.Tensor:\n",
    "\n",
    "        tensor = torch.from_numpy(data).float()\n",
    "        re = torch.autograd.Variable(tensor.cuda()) if self.has_gpu\\\n",
    "            else torch.autograd.Variable(tensor)\n",
    "\n",
    "        return re\n",
    "\n",
    "    '''\n",
    "    Assuming data is an np.ndarray representing remaining data with shape (num_samples, num_possible_values)\n",
    "    This method will calculate the actually batch size according to pseudo batch size and remaining data length\n",
    "    '''\n",
    "    def calculate_batch_size(self, data:np.ndarray):\n",
    "        return self.pseudo_batch if len(data) > self.receptive_field + self.pseudo_batch\\\n",
    "            else len(data)-self.receptive_field\n",
    "\n",
    "    '''\n",
    "    Customized collate_fn\n",
    "    '''\n",
    "    def generate_training_pairs(self, stacked_input):\n",
    "        #stacked_input.shape = (1, num_samples, num_possible_values)\n",
    "\n",
    "        #zero-padding\n",
    "        stacked_input = np.pad(stacked_input, [[0,0], [self.receptive_field,0], [0,0]], 'constant')\n",
    "        #now stacked_input.shape = (1, num_samples+recepetive_field, num_possible_values)\n",
    "\n",
    "        data = stacked_input[0] #data = (num_samples+receptive_field, num_possible_values)\n",
    "                                #Also, num_possible_values are output dim, the inputdim should always be 1\n",
    "        actual_batch_size = self.calculate_batch_size(data)\n",
    "\n",
    "        #build a batch with stupid loop\n",
    "        targets = data[self.receptive_field+1:self.receptive_field+1+actual_batch_size,] \n",
    "        print(targets)\n",
    "        print('next')\n",
    "        targets = targets.reshape((actual_batch_size,1,-1)) #targets.shape=(batch_size, 1, num_possible_values)\n",
    "        print(targets)\n",
    "        \n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f6ac896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n",
      "D:\\LIGN167_Final\\AudioData\\untitled.wav\n",
      "(190882,)\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "       device='cuda:0')\n",
      "next\n",
      "tensor([[8., 8.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "    print('testing')\n",
    "    a = AudioDataLoader(source_folder=r'D:\\LIGN167_Final\\AudioData',receptive_field=8, batch_size=1,num_possible_value=16)\n",
    "    for dataset in a:\n",
    "        for i, n in dataset:\n",
    "            print(i)\n",
    "            print('next')\n",
    "            print(n)\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "19e9d15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.array([[1,2,3],[3,2,1],[2,3,1]])[3:3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40dcbd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
